{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cba6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, dlib\n",
    "import numpy as np\n",
    "import math, sys\n",
    "from dataPath import DATA_PATH\n",
    "from dataPath import MODEL_PATH\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (20.0, 20.0)\n",
    "matplotlib.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cbecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTOR_PATH = MODEL_PATH + \"shape_predictor_68_face_landmarks.dat\"\n",
    "RESIZE_HEIGHT = 480\n",
    "NUM_FRAMES_FOR_FPS = 100\n",
    "SKIP_FRAMES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e942d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interEyeDistance(predict):\n",
    "    leftEyeLeftCorner = (predict[36].x, predict[36].y)\n",
    "    rightEyeRightCorner = (predict[45].x, predict[45].y)\n",
    "    distance = cv2.norm(np.array(rightEyeRightCorner) - np.array(leftEyeLeftCorner))\n",
    "    distance = int(distance)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493c4fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "winName = \"Stabilized facial landmark detector\"\n",
    "cv2.namedWindow(winName, cv2.WINDOW_NORMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af1e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "videoFileName = \"\"\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if(cap.isOpened() == False):\n",
    "    print(\"Unable to load video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6408bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "winSize = 101\n",
    "maxLevel = 10\n",
    "fps = 30.0\n",
    "ret, imPrev = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a76a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "imGrayPrev = cv2.cvtColor(imPrev, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0805c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = imPrev.shape[0:1]\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dc3cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "landmarkDetector = dlib.shape_predictor(PREDICTOR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64f16a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "pointsPrev = []\n",
    "pointsDetectedCur = []\n",
    "pointsDetectedPrev = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e8ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyeDistanceNotCalculated = True\n",
    "eyeDistance = 0\n",
    "isFirstFrame = True\n",
    "fps = 10\n",
    "showStabilized = False\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7427db3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize - 4 things to do in this\n",
    "# 1 - detect the face at lower resolution and getting the bounding box, resize it at highest resolution\n",
    "# 2 - 2 estimates of the location of the landmarks, one using detection we will run the facial landmark \n",
    "# detector on current frame to get an estimate and get estimate for facial landmark \n",
    "# also using the optical flow on the \n",
    "# current frame\n",
    "# 3 - We need to combine these two estimates using alpha, linear combination of these 2 estimates and alpha\n",
    "# is based on how fast the object is moving, fast moving obj - more weight to facial landmark detector,\n",
    "# if the object is not fast moving - more weight to optical flow estimate\n",
    "# 4 -\n",
    "\n",
    "while(True):\n",
    "    if (count == 0):\n",
    "        t = cv2.getTickCount()\n",
    "    \n",
    "    ret, im = cap.read()\n",
    "    imDlib = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    imGray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    height = im.shape[0]\n",
    "    IMAGE_RESIZE = float(height)/RESIZE_HEIGHT\n",
    "    \n",
    "    imSmall = cv2.resize(im, None, fx=1.0/IMAGE_RESIZE, fy=1.0/IMAGE_RESIZE, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    imSmallDlib = cv2.cvtColor(imSmall, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    if (count % SKIP_FRAMES == 0):\n",
    "        faces = detector(imSmallDlib,0)\n",
    "        \n",
    "    if len(faces) == 0 :\n",
    "        print(\"No face detected\")\n",
    "        \n",
    "    else:\n",
    "        for i in range(0, len(faces)):\n",
    "            print(\"Face detected\")\n",
    "            newRect = dlib.rectangle(int(faces[i].left() * IMAGE_RESIZE),\n",
    "                                    int(faces[i].top() * IMAGE_RESIZE),\n",
    "                                    int(faces[i].right() * IMAGE_RESIZE),\n",
    "                                    int(faces[i].bottom() * IMAGE_RESIZE))\n",
    "            \n",
    "            landmarks = landmarkDetector(imDlib, newRect).parts()\n",
    "            \n",
    "            \n",
    "        if(isFirstFrame == True):\n",
    "            pointsPrev = []\n",
    "            pointsDetectedPrev = []\n",
    "            [pointsPrev.append((p.x, p.y)) for p in landmarks]\n",
    "            [pointsDetectedPrev.append((p.x, p.y)) for p in landmarks]\n",
    "            \n",
    "        else:\n",
    "            pointsPrev = [] # result of optical flow\n",
    "            pointsDetectedPrev = [] # result of landmark detecttion in previous frame\n",
    "            pointsPrev = points\n",
    "            pointsDetectedPrev = pointsDetectedCur\n",
    "            \n",
    "        points = [] # points that we are going to output after stabilization\n",
    "        pointsDetectedCur = []\n",
    "        [points.append((p.x, p.y)) for p in landmarks] # this is going to change as we will modify it using optical flow\n",
    "        [pointsDetectedCur.append((p.x, p.y)) for p in landmarks]\n",
    "        \n",
    "        \n",
    "        # convert to numpy float array\n",
    "        pointsArr = np.array(points, np.float32)\n",
    "        pointsPrevArr = np.array(pointsPrev, np.float32)\n",
    "        \n",
    "        # if eye distance is not calculated before\n",
    "        if eyeDistanceNotCalculated:\n",
    "            eyeDistance = interEyeDistance(landmarks)\n",
    "            print(eyeDistance)\n",
    "            eyeDistanceNotCalculated = False\n",
    "            \n",
    "        if eyeDistance > 100:\n",
    "            dotRadius = 3\n",
    "        else:\n",
    "            dotRadius = 2\n",
    "            \n",
    "        print(eyeDistance)\n",
    "        \n",
    "        sigma = eyeDistance * eyeDistance / 400\n",
    "        \n",
    "        s = 2 * int(eyeDistance/4)+1\n",
    "        \n",
    "        lk_params = dict(winSize = (s,s), maxLevel = 5, criteria = (cv2.TERM_CRITERIA_COUNT | cv2.TERM_CRITERIA_EPS, 20, 0.03))\n",
    "        \n",
    "        pointsArr, status, err = cv2.calcOpticalFlowPyrLK(imGrayPrev, imGray, pointsPrevArr, pointsArr, **lk_params)\n",
    "        \n",
    "        pointsArrFloat = np.array(pointsArr, np.float32)\n",
    "        \n",
    "        points = pointsArrFloat.tolist()\n",
    "        \n",
    "        for k in range(0, len(landmarks)):\n",
    "            d = cv2.norm(np.array(pointsDetectedPrev[k]) - np.array(pointsDetectedCur[k]))\n",
    "            alpha = math.exp(-d*d/sigma)\n",
    "            points[k] = (1 - alpha) * np.array(pointsDetectedCur[k]) + alpha * np.array(points[k])\n",
    "            \n",
    "            \n",
    "        if showStabilized is True:\n",
    "            for p in points:\n",
    "                cv2.circle(im, (int(p[0]), int(p[1])), dotRadius, (255, 0, 0), -1)\n",
    "                \n",
    "        else:\n",
    "            for p in pointsDetectedCur:\n",
    "                cv2.circle(im ,(int(p[0]), int(p[1])), dotRadius, (0, 0, 255), -1)\n",
    "        \n",
    "        isFirstFrame = False\n",
    "        count = count + 1\n",
    "        \n",
    "        if (count == NUM_FRAMES_FOR_FPS):\n",
    "            t = (cv2.getTickCount() - t )/ cv2.getTickFrequency()\n",
    "            fps = NUM_FRAMES_FOR_FPS/t\n",
    "            count = 0\n",
    "            isFirstFrame = True\n",
    "            \n",
    "        cv2.putText(im, \"{:.1f}-fps Stabilized = {!s}\".format(fps, showStabilized), (50, size[0]-50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 3, cv2.LINE_AA)\n",
    "        cv2.imshow(winName, im)\n",
    "        key = cv2.waitKey(25) & 0xFF\n",
    "        \n",
    "        # use spacebar to toggle between stabilized and unstabilized version\n",
    "        if key == 32:\n",
    "            showStabilized = not showStabilized\n",
    "        \n",
    "        if key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            cap.release()\n",
    "            sys.exit()\n",
    "        \n",
    "        imPrev = im\n",
    "        imGrayPrev = imGray\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d644e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
